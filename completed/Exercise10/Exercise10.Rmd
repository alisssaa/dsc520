---
title: "Exercise 10"
author: "Alissa Trujillo"
date: '2022-05-17'
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = "/Users/alissa/Documents/Grad/DSC 520/dsc520")
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 58), tidy = TRUE)
```

# Exercise 10

Rmd file:
<https://github.com/alisssaa/dsc520/blob/master/completed/Exercise10/Exercise10.Rmd>

## 1. Thoracic Surgery

### a. Importing the Data

```{r}
setwd("/Users/alissa/Documents/Grad/DSC 520/dsc520")
library(foreign); library(caTools)
thoracicSurgery <- read.arff("data/ThoracicSurgery.arff")
```

In order to make the data a bit easier to read, I am going to create a
new data table including the pertinent information I will be using in my
model. I will be assigning the variables more descriptive names so I am
able to better do analysis.

I will also be converting the Risk1Y variable into a Survival variable.
The Risk1Y determines whether a patient died within the first year after
surgery. The Survival variable, on the other hand, will measure whether
the patient survived the first year. I feel like this is a better
baseline for my model, rather than having the baseline be measuring
death. To do so, I must first convert the Risk1Y into a logical
operator, as it was imported as a factor.

```{r}
thoracicSurgery$Risk1Yr <- as.logical(thoracicSurgery$Risk1Yr)
thoracicSurgery$Survival <- !thoracicSurgery$Risk1Yr

Survival <- thoracicSurgery$Survival
Risk1Y <- thoracicSurgery$Risk1Yr
FVC <- thoracicSurgery$PRE4
Perf <- thoracicSurgery$PRE6
Pain <- thoracicSurgery$PRE7
Haem <- thoracicSurgery$PRE8
Dysp <- thoracicSurgery$PRE9
Cough <- thoracicSurgery$PRE10
Weak <- thoracicSurgery$PRE11
Size <- thoracicSurgery$PRE14
Diab <- thoracicSurgery$PRE17
MI <- thoracicSurgery$PRE19
PAD <- thoracicSurgery$PRE25
Smoke <- thoracicSurgery$PRE30
Asthma <- thoracicSurgery$PRE32
Age <- thoracicSurgery$AGE

thoracicSurgeryX <- data.frame(Risk1Y, Survival, FVC , Perf, Pain, Haem, Dysp, Cough, Weak, Size, Diab, MI, PAD, Smoke, Asthma, Age)

thoracicSplit <- sample.split(thoracicSurgeryX, SplitRatio = 0.75)
thoracicTrain <- subset(thoracicSurgeryX, thoracicSplit == "TRUE")
thoracicValidate <- subset(thoracicSurgeryX, thoracicSplit == "FALSE")
```

### b. Analysis

#### i. Logistic Regression

```{r}
thoracic_Model.1 <- glm(Survival ~ FVC + Perf + Pain + Haem + Dysp + Cough + Weak + Size + Diab + MI + PAD + Smoke + Asthma + Age, data = thoracicTrain, family = binomial())

summary(thoracic_Model.1)
```

#### ii. Variable Analysis

We only had a few variables that had a significant effect on whether a
patient survived the first year after surgery. The first two were in regards
to the size of the tumor, OC13 and OC14. OC11 is the smallest tumor,
which we used as the baseline factor for this variable. A size of OC12,
the next largest tumor, did not seem to have a significant effect on
survival. However, the two larger sizes of tumors OC13 and OC14 did. A
tumor of size OC13 or OC14 was unfortunately significantly correlated
with a patient's failure to survive the first year after their surgery, all other variables held constant. Both OC13 and OC14 were significant at a p = 0.001 level. Dyspnoea before surgery was also indicative of a patient not surviving the first year after surgery, statistically significant at a p = 0.01 level. Weakness before surgery was statistically significant as well, at a p = 0.05 level.

#### iii. Model Accuracy

```{r}
thoracicTestV <- predict(thoracic_Model.1, thoracicValidate, type = "response")
thoracicTestT <- predict(thoracic_Model.1, thoracicTrain, type = "response")

confmatrix <- table(Actual_Value=thoracicTrain$Survival, Predicted_Value = thoracicTestT > 0.5)

confmatrix
```

After using my training data to train my model, I am able to plug in my validation data into my model to see how accurate it is. I split it 75/25 for the purposes of this assignment. Looking at the confusion matrix, we can see that 302 of the values were predicted correctly and 48 were predicted incorrectly. We can calculate the accuracy by dividing the correct responses by the total number of data points:

```{r}
(confmatrix[[1,1]] + confmatrix[[2,2]])/sum(confmatrix)
```
The accuracy of the model is 85.6%. If we had guessed "true" for the one year survival rate for all patients, we would have a model that is accurate that is accurate for 86.4% of the data. Our model is unfortunately less accurate than simply assuming every patient survives the year.

## 2. Logistic Regression Model

### a. Binary Classifier Data

**Importing the Data**

```{r}
setwd("/Users/alissa/Documents/Grad/DSC 520/dsc520")
binary_df <- read.csv("data/binary-classifier-data.csv", header = TRUE)
```

**Creating the Model**

```{r}
binarySplit <- sample.split(binary_df, SplitRatio = 0.75)
binaryTrain <- subset(binary_df, binarySplit == "TRUE")
binaryValidate <- subset(binary_df, binarySplit == "FALSE")

binary_Model.1 <- glm(label ~ x + y, data = binaryTrain, family = binomial())

summary(binary_Model.1)
```

### b. Accuracy

```{r}
binaryTestV <- predict(binary_Model.1, binaryValidate, type = "response")
binaryTestT <- predict(binary_Model.1, binaryTrain, type = "response")

confmatrixB <- table(Actual_Value=binaryTrain$label, Predicted_Value = binaryTestT > 0.5)

confmatrixB

(confmatrixB[[1,1]] + confmatrixB[[2,2]])/sum(confmatrixB)
```

The accuracy of the logistic regression classifier is 58.5%. Simply guessing true or false would result in an accuracy of roughly 50%, so this is a slight improvement on the base model.
